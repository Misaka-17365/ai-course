{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 `NN` 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import override\n",
    "\n",
    "from pathlib import Path\n",
    "from pickle import load, dump\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.sgd import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 上一小节实现的数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistDataset(Dataset):\n",
    "    @override\n",
    "    def __init__(self, x:torch.Tensor, y:torch.Tensor) -> None:\n",
    "        super().__init__()\n",
    "        if len(x) != len(y):\n",
    "            raise IndexError('len(x) != len(y)')\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        return\n",
    "    \n",
    "    @override\n",
    "    def __getitem__(self, index) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    @override\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.x)\n",
    "    \n",
    "    \n",
    "def readDataset(name:str) -> MnistDataset:\n",
    "    fullImgPath = f'./mnistData/{name}-images.idx3-ubyte'\n",
    "    fullLabelPath = f'./mnistData/{name}-labels.idx1-ubyte'\n",
    "\n",
    "    with open(fullImgPath, 'rb') as f:\n",
    "        magic = int.from_bytes(f.read(4))\n",
    "        if magic != 2051:\n",
    "            raise ValueError(f'head magic number not equal to 2051: gotten={magic}')\n",
    "        \n",
    "        dataNumber = int.from_bytes(f.read(4))\n",
    "        dataRow = int.from_bytes(f.read(4))\n",
    "        dataCol = int.from_bytes(f.read(4))\n",
    "        \n",
    "        img = np.fromfile(\n",
    "            file=f, \n",
    "            dtype=np.uint8, \n",
    "            count=dataNumber*dataRow*dataCol,\n",
    "            offset=0,\n",
    "            )\n",
    "    img.shape = (dataNumber,dataRow * dataCol)\n",
    "    imgTensor = torch.from_numpy(img).type(torch.float32) / 255\n",
    "        \n",
    "    with open(fullLabelPath, 'rb') as f:\n",
    "        magic = int.from_bytes(f.read(4))\n",
    "        if magic != 2049:\n",
    "            raise ValueError(f'head magic number not equal to 2049: gotten={magic}')\n",
    "        \n",
    "        dataNumber = int.from_bytes(f.read(4))\n",
    "        \n",
    "        label = np.fromfile(\n",
    "            file=f, \n",
    "            dtype=np.uint8, \n",
    "            count=dataNumber,\n",
    "            offset=0,\n",
    "            )\n",
    "\n",
    "    labelOnehotTensor = torch.zeros((len(label), 10), dtype=torch.float32)\n",
    "    for i,j in zip(label, labelOnehotTensor):\n",
    "        j[i] = 1\n",
    "    \n",
    "    return MnistDataset(imgTensor, labelOnehotTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网络构建\n",
    "\n",
    "构建一个3层的网络，每一每一层使用`ReLU`作为激活函数\n",
    "\n",
    "输出没有归一化，因为后面的损失函数输入不需要归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(28 * 28, 16, True, dtype=torch.float32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 16, True, dtype=torch.float32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 16, True, dtype=torch.float32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 10, True, dtype=torch.float32),\n",
    ")\n",
    "\n",
    "def predict(input):\n",
    "    return torch.softmax(model(input), dim=1)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimisor = SGD(model.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载训练集\n",
    "\n",
    "加载一次训练集之后，打包成`pickle`，下一次使用就不需要重新解析\n",
    "\n",
    "加快加载速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainSetPath = Path(\"./train.pickle\")\n",
    "\n",
    "if trainSetPath.exists():\n",
    "    with open(trainSetPath, \"rb\") as f:\n",
    "        trainSet = load(f)\n",
    "else:\n",
    "    trainSet = readDataset(\"train\")\n",
    "    with open(trainSetPath, \"wb\") as f:\n",
    "        dump(trainSet, f)\n",
    "\n",
    "trainDataLoader = DataLoader(trainSet, 20, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载已经训练的模块\n",
    "\n",
    "每次训练完成后保存\n",
    "\n",
    "如果删除文件则重新训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已加载已有模型：model.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "modelFile = Path(\"./model.pickle\")\n",
    "\n",
    "if modelFile.exists():\n",
    "    with open(modelFile, \"rb\") as f:\n",
    "        model = load(f)\n",
    "    print(f\"已加载已有模型：{modelFile}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始训练\n",
    "\n",
    "可以选择将新的模型覆盖到旧的模型上，也可以不保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练完成\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 0\n",
    "for epoch in range(epochs):\n",
    "    for i, data in enumerate(trainDataLoader):\n",
    "        output = model(data[0])\n",
    "        loss: torch.Tensor = criterion(output, data[1])\n",
    "        optimisor.zero_grad()\n",
    "        loss.backward()\n",
    "        optimisor.step()\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"loss:{float(loss)}\")\n",
    "    for i in optimisor.param_groups:\n",
    "        i[\"lr\"] *= 0.3\n",
    "\n",
    "print(\"训练完成\")\n",
    "\n",
    "# with open(modelFile, \"wb\") as f:\n",
    "#     dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试模型的准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正确率87.17%\n"
     ]
    }
   ],
   "source": [
    "testSet = readDataset(\"t10k\")\n",
    "testDataLoader = DataLoader(testSet, batch_size=100)\n",
    "\n",
    "correctorchount = 0\n",
    "for data in testDataLoader:\n",
    "    output: torch.Tensor = model(data[0])\n",
    "    correction: torch.Tensor = output.argmax(1) == data[1].argmax(1)\n",
    "    correctorchount += int(correction.sum(dtype=torch.int32))\n",
    "\n",
    "print(f\"正确率{correctorchount/100}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
